{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyOFzX00dOYMpm8tG+D0Vqwx",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yukinaga/ai_voice_writing/blob/main/section_1/01_try_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Whisperを使ってみよう！\n",
    "Whisperをインストールし、音声データを文字起こしします。"
   ],
   "metadata": {
    "id": "ek1FW6pNK6M4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "print('abc')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Whisperのインストール\n",
    "「pip」コマンドを使い、Whisperをインストールします。"
   ],
   "metadata": {
    "id": "MQz0MRBkLcDA",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ],
   "metadata": {
    "id": "nnzcQIXZ8Xt_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\r\n",
      "  Cloning https://github.com/openai/whisper.git to /private/var/folders/72/r6gszw592t7bfmkdw7rr8vw40000gn/T/pip-req-build-bixpr3zo\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /private/var/folders/72/r6gszw592t7bfmkdw7rr8vw40000gn/T/pip-req-build-bixpr3zo\r\n",
      "  Resolved https://github.com/openai/whisper.git to commit b38a1f20f4b23f3f3099af2c3e0ca95627276ddf\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting numba\r\n",
      "  Downloading numba-0.58.1-cp39-cp39-macosx_10_9_x86_64.whl (2.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torch\r\n",
      "  Downloading torch-2.1.0-cp39-none-macosx_10_9_x86_64.whl (147.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m147.0/147.0 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tqdm\r\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\r\n",
      "Collecting more-itertools\r\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.8/55.8 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from openai-whisper==20230918) (1.23.2)\r\n",
      "Collecting tiktoken==0.3.3\r\n",
      "  Downloading tiktoken-0.3.3-cp39-cp39-macosx_10_9_x86_64.whl (736 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m736.3/736.3 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting requests>=2.26.0\r\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\r\n",
      "Collecting regex>=2022.1.18\r\n",
      "  Downloading regex-2023.10.3-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.4/296.4 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting llvmlite<0.42,>=0.41.0dev0\r\n",
      "  Downloading llvmlite-0.41.1-cp39-cp39-macosx_10_9_x86_64.whl (31.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m31.0/31.0 MB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting fsspec\r\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sympy in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from torch->openai-whisper==20230918) (1.10.1)\r\n",
      "Collecting filelock\r\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from torch->openai-whisper==20230918) (4.3.0)\r\n",
      "Collecting networkx\r\n",
      "  Downloading networkx-3.2-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m5.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from torch->openai-whisper==20230918) (3.1.2)\r\n",
      "Collecting idna<4,>=2.5\r\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\r\n",
      "Collecting certifi>=2017.4.17\r\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\r\n",
      "Collecting charset-normalizer<4,>=2\r\n",
      "  Downloading charset_normalizer-3.3.1-cp39-cp39-macosx_10_9_x86_64.whl (120 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m120.1/120.1 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting urllib3<3,>=1.21.1\r\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from jinja2->torch->openai-whisper==20230918) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/user_name/GitHub/chemical_projects/venv/lib/python3.9/site-packages (from sympy->torch->openai-whisper==20230918) (1.2.1)\r\n",
      "Building wheels for collected packages: openai-whisper\r\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798398 sha256=47e3965529e0f36e78647b4d3c60423390ddd411db98901a40dbc40fcd614107\r\n",
      "  Stored in directory: /private/var/folders/72/r6gszw592t7bfmkdw7rr8vw40000gn/T/pip-ephem-wheel-cache-2ag78ww3/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\r\n",
      "Successfully built openai-whisper\r\n",
      "Installing collected packages: urllib3, tqdm, regex, networkx, more-itertools, llvmlite, idna, fsspec, filelock, charset-normalizer, certifi, torch, requests, numba, tiktoken, openai-whisper\r\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.3.1 filelock-3.12.4 fsspec-2023.10.0 idna-3.4 llvmlite-0.41.1 more-itertools-10.1.0 networkx-3.2 numba-0.58.1 openai-whisper-20230918 regex-2023.10.3 requests-2.31.0 tiktoken-0.3.3 torch-2.1.0 tqdm-4.66.1 urllib3-2.0.7\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.2.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Whisperによる文字起こし\n",
    "ファイル「sample_voice.m4a」をノートブック上にアップロードした上で、以下のコードを実行します。  \n",
    "音声データが文字に変換されることを確認します。"
   ],
   "metadata": {
    "id": "FFmDy-OiM4SC",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは 音声とAIを作って文章が作れるようになりましょう\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "file_name = \"sample_voice.m4a\"\n",
    "lang = \"ja\"\n",
    "# model = whisper.load_model(\"base\")\n",
    "model = whisper.load_model(\"base\").to('cpu').float()  # モデルをfloat32に変換\n",
    "\n",
    "# 音声データの読み込み\n",
    "audio = whisper.load_audio(file_name)\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# 音響特徴量の計算\n",
    "# mel = whisper.log_mel_spectrogram(audio).cuda()\n",
    "mel = whisper.log_mel_spectrogram(audio).float()      # melテンソルをfloat32に変換\n",
    "\n",
    "\n",
    "# 音声データの文字起こし\n",
    "# options = whisper.DecodingOptions(language=lang, without_timestamps=True)\n",
    "options = whisper.DecodingOptions(language=lang, without_timestamps=True, fp16 = False)\n",
    "result = whisper.decode(model, mel, options)\n",
    "print(result.text)\n",
    "\n",
    "# 結果をファイルに書き込む\n",
    "with open(\"sample_voice.txt\", \"w\") as f:\n",
    "    f.write(result.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}